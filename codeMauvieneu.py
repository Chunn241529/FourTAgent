# @title ğŸ§  2. Khá»Ÿi táº¡o Engine (Tá»± sá»­a lá»—i thiáº¿u thÆ° viá»‡n)
import os
import sys
import subprocess
import warnings
import numpy as np
import re
import soundfile as sf
from IPython.display import Audio, display, clear_output
from google.colab import files
from pydub import AudioSegment

# --- Tá»° Äá»˜NG Sá»¬A Lá»–I THIáº¾U THÆ¯ VIá»†N ---
try:
    import whisper
except ImportError:
    print("ğŸ”§ Äang cÃ i Ä‘áº·t openai-whisper (máº¥t khoáº£ng 20s)...")
    # CÃ i Ä‘áº·t im láº·ng
    subprocess.run("pip install openai-whisper numpy<2.0", shell=True)
    # Reload láº¡i module
    import site
    site.main()
    import whisper
    print("âœ… ÄÃ£ cÃ i xong Whisper!")

from vieneu import Vieneu

# Táº¯t warning
warnings.filterwarnings("ignore")
SAMPLE_RATE = 24000

print("â³ Äang khá»Ÿi táº¡o model TTS & Whisper...")
try:
    # 1. Load TTS
    if 'tts' not in globals():
        tts = Vieneu()

    # 2. Load Whisper
    if 'asr_model' not in globals():
        print("   ...Äang táº£i Whisper AI (Ä‘á»ƒ tá»± nghe giá»ng)...")
        asr_model = whisper.load_model("base")

    print(f"âœ… Há»‡ thá»‘ng sáºµn sÃ ng (TTS + Whisper Auto)")
except Exception as e:
    print(f"âŒ Lá»—i load model: {e}")

# --- CÃ¡c hÃ m xá»­ lÃ½ (Giá»¯ nguyÃªn) ---
def split_text_smart(text):
    return [s.strip() for s in re.split(r'(?<=[.!?\n])\s+', text) if s.strip()]

def infer_long_text(text, voice_data=None, ref_audio=None, ref_text=None):
    sentences = split_text_smart(text)
    full_audio = []
    silence = np.zeros(int(SAMPLE_RATE * 0.3), dtype=np.float32)

    print(f"ğŸ”„ Äang xá»­ lÃ½ {len(sentences)} cÃ¢u...")
    for i, sentence in enumerate(sentences):
        if len(sentence) < 2: continue
        print(f"   Reading ({i+1}/{len(sentences)}): {sentence[:30]}...")
        try:
            result = tts.infer(sentence, voice=voice_data, ref_audio=ref_audio, ref_text=ref_text)
            chunk = result[1] if isinstance(result, tuple) else result

            if chunk is not None and len(chunk) > 0:
                chunk = np.array(chunk).flatten().astype(np.float32)
                full_audio.append(chunk)
                full_audio.append(silence)
        except Exception as e:
            print(f"âš ï¸ Lá»—i cÃ¢u {i+1}: {e}")

    if not full_audio: return None
    return np.concatenate(full_audio)

# --- Wrapper Functions ---
def run_preset(text, voice_index):
    voices = tts.list_preset_voices()
    if voice_index < 0 or voice_index >= len(voices): voice_index = 0
    desc, name = voices[voice_index]
    print(f"ğŸ™ï¸ Giá»ng: {desc}")

    audio_data = infer_long_text(text, voice_data=tts.get_preset_voice(name))
    if audio_data is not None:
        sf.write("output_preset.wav", audio_data, SAMPLE_RATE)
        display(Audio("output_preset.wav", autoplay=True))

def run_clone_auto(text):
    print("\nğŸ“‚ Upload file giá»ng máº«u...")
    uploaded = files.upload()
    if not uploaded: return
    filename = list(uploaded.keys())[0]

    do_cut = input("âœ‚ï¸ Cáº¯t file? (y/n): ").lower()
    final_ref = filename
    if do_cut == 'y':
        try:
            s = float(input("Start (s): "))
            e = float(input("End (s): "))
            audio = AudioSegment.from_file(filename)
            extract = audio[s*1000:e*1000]
            extract.export("ref_sample.wav", format="wav")
            final_ref = "ref_sample.wav"
        except: pass

    print("ğŸ§ AI Ä‘ang nghe file máº«u...")
    try:
        # Tá»± Ä‘á»™ng transcribe
        result = asr_model.transcribe(final_ref, language='vi')
        detected_text = result['text'].strip()
        print(f"ğŸ“ AI nghe Ä‘Æ°á»£c: \"{detected_text}\"")
        if not detected_text: detected_text = "Xin chÃ o tÃ´i lÃ  ngÆ°á»i viá»‡t nam"
    except Exception as e:
        print(f"âš ï¸ Lá»—i Whisper: {e}. DÃ¹ng text máº·c Ä‘á»‹nh.")
        detected_text = "Xin chÃ o"

    audio_data = infer_long_text(text, ref_audio=final_ref, ref_text=detected_text)

    if audio_data is not None:
        sf.write("output_clone.wav", audio_data, SAMPLE_RATE)
        display(Audio("output_clone.wav", autoplay=True))
